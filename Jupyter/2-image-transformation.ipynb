{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Transformations\n",
    "*Author: Vladislav Kim*\n",
    "* [Introduction](#intro)\n",
    "* [Contrast adjustment and image inversion](#contrast)\n",
    "* [Denoising](#noise)\n",
    "* [Thresholding: separate foreground from background](#threshold)\n",
    "* [Morphological operations](#morphology)\n",
    "* [Non-uniform illumination correction](#bgcorrect)\n",
    "\n",
    "\n",
    "<a id=\"intro\"></a> \n",
    "## Introduction\n",
    "\n",
    "Before applying segmentation or training a machine learning model one may have to transform raw images and adjust numerous parameters such as brightness, contrast, noise level. We may also want to combine or split color channels or apply filters that enhance or suppress certain image features. In this notebook we will show a number of preprocessing techniques that may come handy in the context of microscopy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load third-party Python modules\n",
    "import javabridge\n",
    "import bioformats as bf\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "javabridge.start_vm(class_path=bf.JARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by loading the same image of stained nuclei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.utils import read_image\n",
    "img_ho = read_image(fname='data/CLL-coculture/r01c02f01-Hoechst.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images, internally represented as numerical arrays, can have either integer-valued ('uint8', 'uint16') or continuous ('float') pixel intensities. You can learn more about image data types [here](https://scikit-image.org/docs/dev/user_guide/data_types.html). Some functions require images to be of type 'float' and you can use `skimage.img_as_float` function to convert an integer-valued image to a float representation. Note that this image is of type 'float'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ho.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"contrast\"></a> \n",
    "## Contrast adjustment and image inversion\n",
    "It is not uncommon for raw microscopy images be somewhat too dark. To adjust brightness of an image, one may have to apply gamma correction to the image, which simply raises the image represented as `np.array` to the power of `gamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the numpy.array is of dtype 'float'\n",
    "gamma = 0.3\n",
    "img_gamma = img_ho ** gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_gamma, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power transformation (with 0 < `gamma` < 1) shifts pixel intensities to higher values and thus increases brightness. The effect of the transformation can be further assessed by comparing the histograms of the original and power-transformed (gamma-corrected) images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sn.distplot(img_ho, kde=False, label='Original image')\n",
    "sn.distplot(img_gamma, kde=False, label='Gamma-corrected')\n",
    "plt.xlabel('Intensity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases gamma correction is not sufficient and more sophisticated methods such as adaptive histogram equalization (CLAHE) should be used to adjust the contrast of raw images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_adapthist\n",
    "img_adj = equalize_adapthist(img_ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_adj, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sn.distplot(img_ho, kde=False, label='Original image')\n",
    "sn.distplot(img_adj, kde=False, label='CLAHE-adjusted')\n",
    "plt.xlabel('Intensity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that adaptive histogram equalization (`equalize_adapthist`) does not shift the peak of the image histogram, but instead spreads out the distribution of intensity values. This usually results in local contrast enhancement, but histogram equalization may also magnify noise.\n",
    "\n",
    "\n",
    "We will continue working with the gamma-corrected image of the nuclei. Perhaps the most trivial image transformation is image inversion (obtaining the \"negative\" of the image). Given input image `img_gamma` of 'float' data type we can obtain the complement: `1.0 - img_gamma`. In the inverted (negative) image the background is bright and the nuclei appear dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the numpy.array is of dtype 'float'\n",
    "img_neg = 1. - img_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_neg, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sn.distplot(img_gamma, kde=False, label='Original image')\n",
    "sn.distplot(img_neg, kde=False, label='Negative image')\n",
    "plt.xlabel('Intensity')\n",
    "plt.legend(loc='upper center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful feature is image rescaling, which can be achieved by `skimage.transform.resize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of the transformd image\n",
    "img_neg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `resize` we can downsample the original image which has dimensions 2160 x 2160 and convert it to a much smaller image (200 x 200):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "img_small = resize(img_neg, (200, 200), anti_aliasing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up- or downsampling images may introduce artefacts ('aliasing'). If we view the resized image we can see that it's much more pixelated than the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_small, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"noise\"></a> \n",
    "## Denoising\n",
    "Consider the resized negative image: by downsampling it from the original size of (2160 x 2160) to (200 x 200) pixels we introduced some image artefacts. A common approach to address this issue is anti-aliasing which in its simplest form applies Gaussian filter to smooth aliasing effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "img_smooth = gaussian(img_small, sigma=0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.plot import plot_channels\n",
    "plot_channels([img_small, img_smooth], nrow=1, ncol=2, \n",
    "              cmap='gray',\n",
    "              titles = ['Downsampled (200x200)', 'Smoothed (200 x 200)'],\n",
    "             scale_x=6, scale_y=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying Gaussian blur the image appears smoother. Gaussian filter is a common tool for smoothing images. The value of `sigma` has to be tweaked  manually and is usually chosen \"by eye\". Note that there are limits to image denoising and due to almost 10-fold downsampling restoring the original quality would be challenging with simple spatial-domain filters.\n",
    "\n",
    "\n",
    "Depending on the noise model we may have to adapt our denoising strategy. Let's simulate the following noise models:\n",
    "+ Gaussian\n",
    "+ Poisson\n",
    "+ Salt-and-pepper noise\n",
    "+ Speckle noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import random_noise\n",
    "gauss_noisy = random_noise(img_neg, mode='gaussian', var=0.01, seed = 3)\n",
    "poisson_noisy = random_noise(img_neg, mode='poisson', seed = 3)\n",
    "salt = random_noise(img_neg, mode='salt', seed = 12)\n",
    "pepper = random_noise(img_neg, mode='pepper', seed = 3)\n",
    "speckle = random_noise(img_neg, mode='speckle', seed=1)\n",
    "\n",
    "noise_models = ['Gaussian', 'Poisson', 'Salt',\n",
    "                'Pepper', 'Speckle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels([gauss_noisy, poisson_noisy, salt, pepper, speckle],\n",
    "              nrow=2, ncol=3,\n",
    "              titles=noise_models,\n",
    "              scale_x=6, scale_y=6, \n",
    "              cmap='gray')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For salt-and-pepper noise a median filter may be sufficient to denoise the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import median\n",
    "\n",
    "plot_channels([median(salt), median(pepper)],\n",
    "              nrow=1, ncol=2,\n",
    "              titles=['Median-filtered salt noise', 'Median-filtered pepper noise'],\n",
    "              scale_x=6, scale_y=6,\n",
    "              cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Gaussian and speckle noise we can use variational denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import estimate_sigma, denoise_tv_chambolle, denoise_nl_means\n",
    "sigma_est = estimate_sigma(gauss_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels([denoise_tv_chambolle(gauss_noisy, weight=0.3),\n",
    "               denoise_tv_chambolle(speckle, weight=0.2)],\n",
    "              titles=['Gaussian noise reduced by TV Chambolle', 'Speckle noise reduced by TV Chambolle'],\n",
    "              scale_x=6, scale_y=6,\n",
    "              nrow=1, ncol=2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a number of other variational (Bregman total variation, non-local means) and wavelet-transform based denoising methods implemented in `skimage.restoration` module. Note that most of these methods are computationally intensive, e.g. non-local means denoising (in `fast_mode=False`) on 512 x 512 image takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code chunk runs very slowly\n",
    "# uncomment to see how much time it takes\n",
    "'''%%timeit\n",
    "denoise = denoise_nl_means(gauss_noisy[:512,:512],\n",
    "                           h=0.8 * sigma_est, \n",
    "                           fast_mode=False,\n",
    "                           patch_size=10,\n",
    "                           patch_distance=10,\n",
    "                           multichannel=False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read up more on spatial-domain filters in `skimage` [documentation](https://scikit-image.org/docs/dev/api/skimage.filters.html). Variational and wavelet-based denoising techniques are described [here](https://scikit-image.org/docs/dev/api/skimage.restoration.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"threshold\"></a>\n",
    "## Thresholding: separate foreground from background\n",
    "One of the simplest yet useful \"classification\" tasks in image processing is thresholding: sepration of foreground from background pxiels. Most of the classical (non-machine learning) techniques rely on setting a cutoff (threshold) in an image histogram based on a certain criterion.\n",
    "\n",
    "We will use the image with nuclei and try to identify foreground pixels. You can try all available thresholding methods in `skimage` at once by using `try_all_threshold`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import try_all_threshold\n",
    "\n",
    "fig, ax = try_all_threshold(img_gamma, figsize=(8,16), verbose=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A thresholded image is binarized: foreground pixels are white (`1`'s) and the background is black (`0`'s). Note that some methods are extremely conservative: Yen and minimum thresholding remove all large low-intensity nuclei and leave only few bright spots. Mean thresholding on the other hand retains all low-intensity nuclei (and some noise), while Otsu and triangle methods are somehwat in-between.\n",
    "\n",
    "Note that we applied thresholding to the power-transformed image `img_gamma`. Had we used the  raw image `img_ho` instead, the results would have been different (uncomment the following code block to see the result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fig, ax = try_all_threshold(img_gamma, figsize=(8,16), verbose=False)\n",
    "plt.tight_layout()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on `try_all_threshold` output one could for example choose Otsu method to separate foreground from background. Function `threshold_otsu` returns the cutoff value for foreground pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "th = threshold_otsu(img_gamma)\n",
    "\n",
    "\n",
    "sn.distplot(img_gamma, kde=False, label='Image histogram')\n",
    "plt.axvline(th, color='red', label='Otsu threshold')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold the image based on the obtained value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_th = img_gamma.copy()\n",
    "img_th[img_th < th] = 0\n",
    "img_th[img_th >= th] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best is always to compare the original and transformed image side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels([img_gamma, img_th], nrow=1, ncol=2,\n",
    "             titles=['Image', 'Thresholded by Otsu method'],\n",
    "             cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"morphology\"></a> \n",
    "## Morphological operations\n",
    "Some image preprocessing steps such as thresholding may introduce discontinuities (e.g. holes inside nuclei) in transformed images or merge objects that are close to one another. We can address such issues using morphological operations which can alter shape, size or connectivity in binarized images.\n",
    "\n",
    "\n",
    "Some of the most common morphological opearations are:\n",
    "+ dilation\n",
    "+ erosion\n",
    "+ opening\n",
    "+ closing\n",
    "\n",
    "We can apply these operations that are available in `skimage.morphology` module to our thresholded image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the thresholded image is binary\n",
    "print(np.unique(img_th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify neighborhood element\n",
    "from skimage.morphology import disk\n",
    "selem = disk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_dilation, binary_erosion, binary_closing, binary_opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilated = binary_dilation(img_th, selem)\n",
    "eroded = binary_erosion(img_th, selem)\n",
    "opened = binary_opening(img_th, selem)\n",
    "closed = binary_closing(img_th, selem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphs = ['Original', 'Dilation', 'Erosion',\n",
    "         'Opening', 'Closing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels([img_th, dilated, eroded, opened, closed],\n",
    "              nrow=2, ncol=3,\n",
    "              titles=morphs,\n",
    "              scale_x=6, scale_y=6, \n",
    "              cmap='gray')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bgcorrect\"></a>\n",
    "## Non-uniform illumination correction\n",
    "Occasionally micrsocopy images may have non-uniform illumination: e.g. one side of the image appears darker due to uneven illumination. We can correct such issues using background subtraction. \n",
    "\n",
    "Let's load an image of leukemia cells stained with surface marker antibody:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = read_image(fname=\"data/BiTE/Tag1r02c02-APC.tiff\")\n",
    "mip = img**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we appply thresholding directly to this image, we will see that some methods overestimate the number of foreground pixels in the lower right corner due to non-uniform illumination (which is not easy to spot by simply looking at the original image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = try_all_threshold(mip**0.5, figsize=(8,16), verbose=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can estimate the background and subtract it from the original image in order to correct non-uniform illumination. The most straightforward way to estimate the background of an image is to apply a Gaussian blur with a large $\\sigma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate background using large 'sigma'\n",
    "bg = gaussian(mip, sigma=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original with background subtracted\n",
    "bgsub = mip - bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Original', 'Estimated background ($\\sigma=200$)', 'Background-subtracted']\n",
    "plot_channels([mip, bg, bgsub],\n",
    "              ncol=3,nrow=1,\n",
    "              cmap='gray',\n",
    "              titles=titles,\n",
    "              scale_x=6, scale_y=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After background subtraction Li and mean thresholding becomes more uniform and less fixated on the lower-right corner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = try_all_threshold(bgsub, figsize=(8,16), verbose=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
