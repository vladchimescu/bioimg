{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Segmentation\n",
    "*Author: Vladislav Kim*\n",
    "* [Introduction](#intro)\n",
    "* [Connected component labelling](#connectedcomp)\n",
    "* [Watershed and random-walk segmentation](#watershed)\n",
    "* [Spot detector for segmentation of nuclei](#spotdetect)\n",
    "\n",
    "\n",
    "<a id=\"intro\"></a> \n",
    "## Introduction\n",
    "One of the essential problems in bioimage analysis is instance segmentation or partitoning of the image into individual objects such as cells, nuclei, filaments, organelles, etc. This step is crucial since we are interested in characterizing the morphology and quantifying key phenotypic parameters of individual objects. In this notebook we will work on nucleus segmentation in leukemia cells and will explore the classical segmentation approaches that do not rely on machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load third-party Python modules\n",
    "import javabridge\n",
    "import bioformats as bf\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "javabridge.start_vm(class_path=bf.JARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by loading the image stack, applying maximum intensity projection (MIP) and thresholding the image using Otsu method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.utils import load_imgstack\n",
    "imgstack = load_imgstack(fname=\"data/BiTE/Tag2-r04c02f1.tiff\")\n",
    "mip=np.max(imgstack, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.process import threshold_img\n",
    "from base.plot import plot_channels\n",
    "\n",
    "hoechst = mip[:,:,2]**0.4\n",
    "# threshold the image of nuclei\n",
    "img_th = threshold_img(hoechst, method='otsu', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thresholded image is binarized (`binary=True`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels([hoechst, img_th],nrow=1, ncol=2,\n",
    "             titles=['Image of nuclei', 'Thresholded image'],\n",
    "             cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"connectedcomp\"></a> \n",
    "## Connected component labelling\n",
    "Thresholding  has already separated most of the foreground pixels from the dark background. We can use connected component labelling to partition this binarized image of nuclei into islands of connected foreground pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "from skimage.color import label2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm = label(img_th, connectivity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `label` function performs connected component labelling (with a 4-neighbor scheme by default). It returns an array with the same shape as the original image but with every pixel labelled as belonging to one of the connected components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract one component (background label = 0)\n",
    "print(\"Found %d unique labels (connected components)\" % (len(np.unique(segm)) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `label2rgb` function to overlay the identified connected components  with the original  image of the nuclei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm, image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the color indicates pixel label, i.e. which connected component the pixel belongs to. In many cases individual nuclei are identified (\"segmented\") using this simple heuristic. There are however a number of grape-shaped clusters of merged nuclei which could not be separated from one another and which form a single connected region. Note that the colors are cycled, i.e. repeated in some cases for regions with different labels. \n",
    "\n",
    "\n",
    "Once an image is labeled, we can use `regionprops` function to extract various image features for the individual labelled components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats =  regionprops(label_image=segm, intensity_image=hoechst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 780 connected components there is a number of region properties that were computed with the call of `regionprops`. The keys of the features are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_keys = [f for f in feats[0]]\n",
    "print(feat_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract some of these features and plot their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feattable(feats, keys):\n",
    "    return pd.DataFrame({key: [f[key] for f in feats] for key in keys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `get_feattable` extracts only the features that are specified in the list `keys` and returns a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = get_feattable(feats, keys=['area', 'eccentricity', 'mean_intensity', 'perimeter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a pairs plot to visualize the relation between these four variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.pairplot(feat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the connected components based on their image features such as perimter or eccentricity. For example we can subset only those regions that have perimeter < 200 pixels and area  <  1000 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_subset = np.logical_and(feat_df.area < 1000, feat_df.perimeter < 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label count of non-background objects starts with 1\n",
    "label_subset = np.where(feat_subset)[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm*np.isin(segm, label_subset), image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the labelling has been subset to inlcude only the small connected regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"watershed\"></a> \n",
    "## Watershed and random-walk segmentation\n",
    "One of the most widely used classical segmentation algorithms is watershed, which considers the intensity image as a landscape and \"fills\" the basins (local minima) of the gradient image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import sobel\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "import scipy.ndimage as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient image\n",
    "img_grad = sobel(hoechst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the gradient of the image as a  surface. To speed up the 3D plotting subset to only the upper corner (200 x 200 patch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from matplotlib import cm\n",
    "\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "\n",
    "ax1 = fig.add_subplot(1,2,1,projection='3d')\n",
    "x, y = np.meshgrid(\n",
    "    np.arange(0, 200, 1),\n",
    "    np.arange(0, 200, 1)\n",
    ")\n",
    "ax1.plot_trisurf(x.ravel(), y.ravel(),\n",
    "                np.ravel(img_grad[:200,:200]),\n",
    "                linewidth=0.1,\n",
    "                cmap=cm.viridis,\n",
    "                antialiased=True)\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(img_grad[:200,:200])\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the intensity \"landscpae\" and the gradient image side by side: high ridges correspond to bright regions in the gradient image (edges). The \"basins\" are encompassed by these ridges and will be filled by watershed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm = watershed(img_grad,\n",
    "                 markers=1000, \n",
    "                 mask=img_th.astype(bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we additionally provided `markers=1000`, number of random seeds at which the basin filling is initiated, and `mask`, which is simply the boolean mask of the foreground pixels. We provide the mask so that the water does not spill into the background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm, image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the segmentation generated by watershed using `label2rgb` function that we used to overlay connected component labels with the original image of the nuclei. We see that the segmentation is quite poor - many nuclei are not identified (merged with background) or merged into large clusters.\n",
    "\n",
    "Instead of random seeding one can compute local minima in the gradient image (which correspond to local maxima in the intensity image) and provide these as initial seeding sites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = peak_local_max(hoechst, indices=False, min_distance=10)\n",
    "\n",
    "\n",
    "segm = watershed(img_grad,\n",
    "                 markers=nd.label(markers)[0], \n",
    "                 mask=img_th.astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm, image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watershed segmentation with local minima (of the image gradient) as starting seeds is much better than the one generated with randomly initialized markers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot detector for segmentation of nuclei\n",
    "<a id=\"spotdetect\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.process import threshold_img\n",
    "from skimage.feature import blob_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_th = threshold_img(hoechst, method='otsu')\n",
    "blobs = blob_log(img_th,\n",
    "                 min_sigma=10, max_sigma=12, threshold=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful transformation is `shape_index` which is a measure of local curvature of the intensity landscape at every pixel. In the intensity landscape bright regions are ridges and hills, while the image background is a flat planar surface. Shape index maps every pixel value to the $[-1,1]$ range, with concave landscape pixels becoming negative, while convex regions (e.g. bright spots) are mapped to positive values.\n",
    "\n",
    "Thus hape index will enhance the appearance of the bright spots. Image background (flat intensity landscape) will get `NaN` values after shape index is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import shape_index\n",
    "from segment.cv_methods import nantonum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_s = shape_index(img_th)\n",
    "print(\"Number of NaN pixels: %d\" % np.sum(np.isnan(img_s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the `NaN`-valued pixels are most likely background pixels. We can convert `NaN` values to -1 using `nantonum` function and detect blobs in this enhanced image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_enh = nantonum(img_s, pad=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_enh, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run LoG blob detection on the shape-index enhanced image\n",
    "blobs_enh = blob_log(img_enh,\n",
    "                 min_sigma=9, max_sigma=11, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "for blob in blobs:\n",
    "    y, x, r = blob\n",
    "    c = plt.Circle((x, y), r-2, color='yellow', linewidth=1.4, fill=False)\n",
    "    ax.add_patch(c)\n",
    "for blob in blobs_enh:\n",
    "    y, x, r = blob\n",
    "    c = plt.Circle((x, y), r+2, color='magenta', linewidth=1.4, fill=False)\n",
    "    ax.add_patch(c)\n",
    "ax.imshow(hoechst, cmap='gray')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some of the low-intensity spots are captured now if we use `blob_log` on an enhanced image because shape index only transforms the image based on local curvature of the landscape (weak spots are also \"hills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
