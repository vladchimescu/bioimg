{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Segmentation\n",
    "*Author: Vladislav Kim*\n",
    "* [Introduction](#intro)\n",
    "* [Connected component labelling](#connectedcomp)\n",
    "* [Watershed segmentation](#watershed)\n",
    "* [Spot detector for segmentation of nuclei](#spotdetect)\n",
    "\n",
    "\n",
    "<a id=\"intro\"></a> \n",
    "## Introduction\n",
    "One of the essential problems in bioimage analysis is instance segmentation or partitoning of the image into individual objects such as cells, nuclei, filaments, organelles, etc. This step is crucial since we are interested in characterizing the morphology and quantifying key phenotypic parameters of individual objects. In this notebook we will work on nucleus segmentation in leukemia cells and will explore the classical segmentation approaches that do not rely on machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load third-party Python modules\n",
    "import javabridge\n",
    "import bioformats as bf\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "javabridge.start_vm(class_path=bf.JARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by loading the image stack, applying maximum intensity projection (MIP) and thresholding the image using Otsu method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.utils import load_imgstack\n",
    "imgstack = load_imgstack(fname=\"data/BiTE/Tag2-r04c02f1.tiff\")\n",
    "mip=np.max(imgstack, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.process import threshold_img\n",
    "from base.plot import plot_channels\n",
    "\n",
    "hoechst = mip[:,:,2]**0.4\n",
    "# threshold the image of nuclei\n",
    "img_th = threshold_img(hoechst, method='otsu', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thresholded image is binarized (`binary=True`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels([hoechst, img_th],nrow=1, ncol=2,\n",
    "             titles=['Image of nuclei', 'Thresholded image'],\n",
    "             cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"connectedcomp\"></a> \n",
    "## Connected component labelling\n",
    "Ideally, thresholding  should have already separated the foreground pixels from the dark background. We can use connected component labelling to partition this binarized image of nuclei into islands of connected foreground pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "from skimage.color import label2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm = label(img_th, connectivity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `label` function performs connected component labelling (with a 4-neighbor scheme by default, `connectivity=1`). It returns an array with the same shape as the original image but with every pixel labelled as belonging to one of the connected components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The background label is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract one component (background label = 0)\n",
    "print(\"Found %d unique labels (connected components)\" % (len(np.unique(segm)) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `label2rgb` function to overlay the identified connected components  with the original  image of the nuclei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm, image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the color indicates pixel label, i.e. which connected component the pixel belongs to. In many cases individual nuclei are identified (\"segmented\") using this simple heuristic. There are however a number of grape-shaped clusters of merged nuclei which could not be separated from one another and which form a single connected region. Note that the colors are cycled, i.e. repeated in some cases for regions with different labels. \n",
    "\n",
    "\n",
    "Once an image is labeled, we can use `regionprops` function to extract various image features for the individual labelled components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats =  regionprops(label_image=segm, intensity_image=hoechst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 780 connected components there is a number of region properties that were computed with the call of `regionprops`. The keys of the features are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_keys = [f for f in feats[0]]\n",
    "print(feat_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract some of these features and plot their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feattable(feats, keys):\n",
    "    return pd.DataFrame({key: [f[key] for f in feats] for key in keys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `get_feattable` extracts only the features that are specified in the list `keys` and returns a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = get_feattable(feats, keys=['area', 'eccentricity', 'mean_intensity', 'perimeter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a pairs plot to visualize the relation between these four variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.pairplot(feat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the connected components based on their image features such as perimter or eccentricity. For example we can subset only those regions that have perimeter < 200 pixels and area  <  1000 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_subset = np.logical_and(feat_df.area < 1000, feat_df.perimeter < 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label count of non-background objects starts with 1\n",
    "label_subset = np.where(feat_subset)[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm*np.isin(segm, label_subset), image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the labelling has been subset to inlcude only the small connected regions - most of them are the nuclei that were segmented correctly, i.e. separated from one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"watershed\"></a> \n",
    "## Watershed segmentation\n",
    "One of the most widely used classical segmentation algorithms is watershed, which considers the intensity image as a landscape and \"fills\" the basins (local minima) of the gradient image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import sobel\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "import scipy.ndimage as nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobel filter computes image gradient approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient image\n",
    "img_grad = sobel(hoechst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the gradient of the image as a  surface. To speed up the 3D plotting select only the upper corner (200 x 200 patch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from matplotlib import cm\n",
    "\n",
    "fig = plt.figure(figsize=(16,7))\n",
    "\n",
    "ax1 = fig.add_subplot(1,2,1,projection='3d')\n",
    "x, y = np.meshgrid(\n",
    "    np.arange(0, 200, 1),\n",
    "    np.arange(0, 200, 1)\n",
    ")\n",
    "ax1.plot_trisurf(x.ravel(), y.ravel(),\n",
    "                np.ravel(img_grad[:200,:200]),\n",
    "                linewidth=0.1,\n",
    "                cmap=cm.viridis,\n",
    "                antialiased=True)\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(img_grad[:200,:200])\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can view the intensity \"landscape\" and the gradient image side by side: the spikes correspond to the bright regions in the gradient image (edges). The \"basins\" are encompassed by these ridges and will be filled by watershed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm = watershed(img_grad,\n",
    "                 markers=1000, \n",
    "                 mask=img_th.astype(bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provided the argument `markers=1000`, which specifies the number of random seeds at which the basin filling is initiated, and `mask`, which is simply the boolean mask of the foreground pixels. We provide the mask so that the watershed does not flood or spill into the background. \n",
    "\n",
    "We can visualize the segmentation generated by watershed using `label2rgb` function that we used to overlay connected component labels with the original image of the nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm, image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the segmentation is quite poor - many nuclei are not detected or merged into large clusters. Instead of random seeding one can compute local minima in the gradient image (which correspond to local maxima in the intensity image) and provide these as initial seeding sites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = peak_local_max(hoechst, indices=False, min_distance=10)\n",
    "\n",
    "segm = watershed(img_grad,\n",
    "                 markers=nd.label(markers)[0], \n",
    "                 mask=img_th.astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm, image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The watershed segmentation with local minima as starting points is much better than the one generated with randomly initialized markers. We also note that in contrast to connected component labelling some of the nucleus clusters are partially segmented. Computing region properties with `regionprops` can be further used to remove small artefacts in these big clusters and clean up the segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"spotdetect\"></a>\n",
    "## Spot detector for segmentation of nuclei\n",
    " Since the nuclei are mostly circular, we can use blob detection to detect and count them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.process import threshold_img\n",
    "from skimage.feature import blob_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_th = threshold_img(hoechst, method='otsu', binary=False)\n",
    "blobs = blob_log(img_th,\n",
    "                 min_sigma=10, max_sigma=12, threshold=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already discussed blob detection based on LoG operator in the [previous](https://github.com/vladchimescu/bioimg/blob/master/Jupyter/3-image-filters.ipynb) notebook. There we had a problem that some of the nuclei in clusters were not detected.\n",
    "\n",
    "A useful transformation is `shape_index` which is a measure of local curvature of the intensity landscape at every pixel. In the intensity landscape bright regions are ridges and hills, while the image background is a flat planar surface. Shape index maps every pixel value to the $[-1,1]$ range, with concave landscape pixels becoming negative, while convex regions (e.g. bright spots) are mapped to positive values.\n",
    "\n",
    "Thus shape index will enhance the appearance of the bright spots. Image background (flat intensity landscape) will get `NaN` values after shape index is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import shape_index\n",
    "from segment.cv_methods import nantonum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_s = shape_index(img_th)\n",
    "print(\"Number of NaN pixels: %d\" % np.sum(np.isnan(img_s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the `NaN`-valued pixels are background pixels. We can convert `NaN` values to -1 using `nantonum` function and detect blobs in this enhanced image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_enh = nantonum(img_s, pad=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_enh, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.colorbar(fraction=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bright spots are enhanced, i.e. shifted towards higher values by the shape index. We can now run blob detection `blob_log` on this enhanced image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run LoG blob detection on the shape-index enhanced image\n",
    "blobs_enh = blob_log(img_enh,\n",
    "                 min_sigma=9, max_sigma=11, threshold=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the original `blobs` (plotted in yellow) with the shape-index enhanced `blobs_enh` (magenta):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "for blob in blobs:\n",
    "    y, x, r = blob\n",
    "    c = plt.Circle((x, y), r-2, color='yellow', linewidth=1.4, fill=False)\n",
    "    ax.add_patch(c)\n",
    "for blob in blobs_enh:\n",
    "    y, x, r = blob\n",
    "    c = plt.Circle((x, y), r+2, color='magenta', linewidth=1.4, fill=False)\n",
    "    ax.add_patch(c)\n",
    "ax.imshow(hoechst, cmap='gray')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some of the low-intensity spots are captured now if we use `blob_log` on an enhanced image because shape index only transforms the image based on local curvature of the landscape - weak-intensity spots are also \"hills\" and hence get picked up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
