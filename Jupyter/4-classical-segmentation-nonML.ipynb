{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Segmentation\n",
    "*Author: Vladislav Kim*\n",
    "* [Introduction](#intro)\n",
    "* [Connected component labelling](#connectedcomp)\n",
    "* [Watershed and random-walk segmentation](#watershed)\n",
    "* [Spot detector for segmentation of nuclei](#spotdetect)\n",
    "\n",
    "\n",
    "<a id=\"intro\"></a> \n",
    "## Introduction\n",
    "One of the essential problems in bioimage analysis is instance segmentation or partitoning of the image into individual objects such as cells, nuclei, filaments, organelles, etc. This step is crucial since we are interested in characterizing the morphology and quantifying key phenotypic parameters of individual objects. In this notebook we will work on nucleus segmentation in leukemia cells and will explore the classical segmentation approaches that do not rely on machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load third-party Python modules\n",
    "import javabridge\n",
    "import bioformats as bf\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "javabridge.start_vm(class_path=bf.JARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by loading the image stack, applying maximum intensity projection (MIP) and thresholding the image using Otsu method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.utils import load_imgstack\n",
    "imgstack = load_imgstack(fname=\"data/BiTE/Tag2-r04c02f1.tiff\")\n",
    "mip=np.max(imgstack, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.process import threshold_img\n",
    "from base.plot import plot_channels\n",
    "\n",
    "hoechst = mip[:,:,2]**0.4\n",
    "# threshold the image of nuclei\n",
    "img_th = threshold_img(hoechst, method='otsu', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thresholded image is binarized (`binary=True`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels([hoechst, img_th],nrow=1, ncol=2,\n",
    "             titles=['Image of nuclei', 'Thresholded image'],\n",
    "             cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"connectedcomp\"></a> \n",
    "## Connected component labelling\n",
    "Thresholding  has already separated most of the foreground pixels from the dark background. We can use connected component labelling to partition this binarized image of nuclei into islands of connected foreground pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "from skimage.color import label2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm = label(img_th, connectivity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `label` function performs connected component labelling (with a 4-neighbor scheme by default). It returns an array with the same shape as the original image but with every pixel labelled as belonging to one of the connected components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Found %d unique labels (connected components)\" % (len(np.unique(segm)) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `label2rgb` function to overlay the identified connected components  with the original  image of the nuclei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm, image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the color indicates pixel label, i.e. which connected component the pixel belongs to. In many cases individual nuclei are identified (\"segmented\") using this simple heuristic. There are however a number of grape-shaped clusters of merged nuclei which could not be separated from one another and which form a single connected region. Note that the colors are cycled, i.e. repeated in some cases for regions with different labels. \n",
    "\n",
    "\n",
    "Once an image is labeled, we can use `regionprops` function to extract various region features for the individual labelled components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats =  regionprops(label_image=segm, intensity_image=hoechst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 780 connected components there is a number of region properties that were computed with the call of `regionprops`. The keys of the features are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_keys = [f for f in feats[0]]\n",
    "print(feat_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract some of these features and plot their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feattable(feats, keys):\n",
    "    return pd.DataFrame({key: [f[key] for f in feats] for key in keys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = get_feattable(feats, keys=['area', 'eccentricity', 'mean_intensity', 'perimeter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.pairplot(feat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershed and random-walk segmentation\n",
    "<a id=\"watershed\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot detector for segmentation of nuclei\n",
    "<a id=\"spotdetect\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.process import threshold_img\n",
    "from skimage.feature import blob_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_th = threshold_img(hoechst, method='otsu')\n",
    "blobs = blob_log(img_th,\n",
    "                 min_sigma=10, max_sigma=12, threshold=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful transformation is `shape_index` which is a measure of local curvature of the intensity landscape at every pixel. In the intensity landscape bright regions are ridges and hills, while the image background is a flat planar surface. Shape index maps every pixel value to the $[-1,1]$ range, with concave landscape pixels becoming negative, while convex regions (e.g. bright spots) are mapped to positive values.\n",
    "\n",
    "Thus hape index will enhance the appearance of the bright spots. Image background (flat intensity landscape) will get `NaN` values after shape index is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import shape_index\n",
    "from segment.cv_methods import nantonum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_s = shape_index(img_th)\n",
    "print(\"Number of NaN pixels: %d\" % np.sum(np.isnan(img_s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the `NaN`-valued pixels are most likely background pixels. We can convert `NaN` values to -1 using `nantonum` function and detect blobs in this enhanced image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_enh = nantonum(img_s, pad=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img_enh, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run LoG blob detection on the shape-index enhanced image\n",
    "blobs_enh = blob_log(img_enh,\n",
    "                 min_sigma=9, max_sigma=11, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "for blob in blobs:\n",
    "    y, x, r = blob\n",
    "    c = plt.Circle((x, y), r-2, color='yellow', linewidth=1.4, fill=False)\n",
    "    ax.add_patch(c)\n",
    "for blob in blobs_enh:\n",
    "    y, x, r = blob\n",
    "    c = plt.Circle((x, y), r+2, color='magenta', linewidth=1.4, fill=False)\n",
    "    ax.add_patch(c)\n",
    "ax.imshow(hoechst, cmap='gray')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some of the low-intensity spots are captured now if we use `blob_log` on an enhanced image because shape index only transforms the image based on local curvature of the landscape (weak spots are also \"hills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
