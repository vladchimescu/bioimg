{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label image data in plate 180528_Plate3\n",
    "*Vladislav Kim*\n",
    "\n",
    "\n",
    "* [Introduction](#1)\n",
    "* [Initial training set](#2)\n",
    "\n",
    "<a id=\"1\"></a> \n",
    "## Introduction\n",
    "The idea of this notebook series is to train a pseudo-online random forest classifier for AML vs stroma cell classification. From selected plates we (for now) sample 6 DMSO wells with the highest Calcein cell count, generate predictions and correct misclassified instances and check in live (\"online\") mode how the predictions improve as we add more data. Note that the classifier is not truly an online classifier as we don't update the model as we go, but completely retrain the RF classfier in multicore mode.\n",
    "\n",
    "In general we can implement targeted online learning strategy: we can select a number of wells that are of interest to us (target wells), e.g. DMSO control wells or wells with certain high-priority drugs, the accuracy of which we want to improve, in the first place. We sample from these target wells from selected plates and evaluate the classification accuracy as we go (pseudo online learning).\n",
    "\n",
    "\n",
    "<a id=\"2\"></a>\n",
    "## Initial Training Set: 180528_Plate3\n",
    "At first we will re-train the classifier on the plate `180528_Plate3`, as it manifests a very striking contrast between mono- and co-cultures. We want to rule out the fact that this could be a segmentation (classification in this case) artefact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load third-party Python modules\n",
    "import javabridge\n",
    "import bioformats as bf\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../..')\n",
    "\n",
    "javabridge.start_vm(class_path=bf.JARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.utils import load_imgstack\n",
    "imgstack = load_imgstack(fname=\"../../data/AML_trainset/180528_Plate3/r02c14.tiff\")\n",
    "\n",
    "# remove a 'dummy' z-axis\n",
    "img = np.squeeze(imgstack)\n",
    "\n",
    "# nuclei\n",
    "hoechst = img[:,:,0]**0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/AML_trainset/180528_Plate3/r02c14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment.tools import read_bbox\n",
    "rmax, cmax = hoechst.shape\n",
    "\n",
    "bbox = read_bbox(df=df, rmax=rmax, cmax=cmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.plot import show_bbox\n",
    "#show_bbox(hoechst, bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotly visualization works!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extra.viz import plotly_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_adapthist\n",
    "gamma = 0.3\n",
    "img_g = img**gamma\n",
    "mip_rgb = equalize_adapthist(np.dstack((img_g[:,:,1],\n",
    "                                        img_g[:,:,2],\n",
    "                                        img_g[:,:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout, cells = plotly_viz(mip_rgb, bb=bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extra.viz import plotly_predictions\n",
    "ypred = np.zeros(len(bbox), dtype=np.int)\n",
    "labels = ['cells']\n",
    "layout, cells = plotly_predictions(img=mip_rgb, bb=bbox,\n",
    "                                  ypred=ypred, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iplot(dict(data=cells, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_instance(path, fname, pad=0):\n",
    "    imgstack = load_imgstack(fname=os.path.join(path, fname + \".tiff\"),\n",
    "                            verbose=False)\n",
    "    img = np.squeeze(imgstack)\n",
    "    df = pd.read_csv(os.path.join(path, fname + \".csv\"))\n",
    "    rmax, cmax, _ = img.shape\n",
    "    bbox = read_bbox(df=df, rmax=rmax,\n",
    "                     cmax=cmax, pad=pad)\n",
    "    return img, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, bbox = get_train_instance(path='../../data/AML_trainset/180528_Plate3',\n",
    "                              fname='r02c14', pad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here need to fix how we import `ImgX`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../../')\n",
    "from bioimg.classify import ImgX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgx_test = ImgX(img=img**0.4, bbox=bbox)\n",
    "imgx_test = imgx_test.compute_props(n_chan=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgx_test.data[0].iloc[:10,:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement a class that has `ImgX` instance and can accumulate training data:**\n",
    "+ How to do proper class composition, i.e. `IncrementalClassifier` **has** `ImgX`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalClassifier:\n",
    "    def __init__(self, imgx):\n",
    "        # initialize with 'None' something to be loaded later\n",
    "        self.imgx = imgx\n",
    "        self.newlabels = None\n",
    "        # training data\n",
    "        self.Xtrain = None\n",
    "        # inialize classifier as 'None'\n",
    "        self.clf = None\n",
    "        self.pca = None\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self.__dict__[name] = value\n",
    "\n",
    "    # function for setting individual class parameters\n",
    "    def set_param(self, **kwargs):\n",
    "        for k in kwargs.keys():\n",
    "            self.__setattr__(k, kwargs[k])\n",
    "            \n",
    "    def set_classifier(self, n_components=150,\n",
    "                         bootstrap=True,\n",
    "                         max_depth=None,\n",
    "                         n_estimators=100,\n",
    "                         max_features='sqrt',\n",
    "                         min_samples_split=5,\n",
    "                         min_samples_leaf=5,\n",
    "                         random_state=100):\n",
    "        self.pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "                       whiten=True, random_state=random_state).fit(self.X_train_norm)\n",
    "        \n",
    "        self.clf = RandomForestClassifier(bootstrap=bootstrap,\n",
    "                                          class_weight=\"balanced\",\n",
    "                                          max_depth=max_depth,\n",
    "                                          n_estimators=n_estimators,\n",
    "                                          max_features=max_features,\n",
    "                                          min_samples_split=min_samples_split,\n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          random_state=random_state,\n",
    "                                          n_jobs=-1)\n",
    "        return self\n",
    "    \n",
    "    def train_classifier(self):\n",
    "        # project the train data\n",
    "        X_train_pca = self.pca.transform(self.X_train_norm)\n",
    "        X_train_all = np.append(X_train_pca, self.X_train_prop, axis=1)\n",
    "\n",
    "        self.clf.fit(X_train_all, self.y_train)\n",
    "        return self\n",
    "\n",
    "    # generate predictions with the loaded feature data\n",
    "    def generate_predictions(self, prob=False):\n",
    "        if self.X_test_norm is None:\n",
    "            cellbb_norm = [resize(cb, (self.w, self.h), anti_aliasing=True)\n",
    "                           for cb in self.cellbb]\n",
    "            self.X_test_norm = np.array([cbn.ravel() for cbn in cellbb_norm])\n",
    "\n",
    "        if self.X_test_prop is None:\n",
    "            X_prop_list = [get_regionprop_feats(\n",
    "                mip_rgb=cbb, exclude=exclude) for cbb in self.cellbb]\n",
    "            self.X_test_prop = np.vstack(X_prop_list)\n",
    "\n",
    "        X_test_pca = self.pca.transform(self.X_test_norm)\n",
    "        X_test_all = np.append(X_test_pca, self.X_test_prop, axis=1)\n",
    "\n",
    "        self.y_pred = self.clf.predict(X_test_all)\n",
    "        if prob:\n",
    "            self.y_prob = self.clf.predict_proba(X_test_all)\n",
    "        return self\n",
    "\n",
    "    # set plotly graphical layers\n",
    "    def set_scene(self):\n",
    "        # derived object attributes\n",
    "        wellpos = convert_well_name(self.select_well)\n",
    "\n",
    "        mip = fn.get_mip(path=self.path, wellpos=wellpos)\n",
    "        mip_rgb = equalize_adapthist(np.dstack((mip[:, :, 1],\n",
    "                                                mip[:, :, 2],\n",
    "                                                mip[:, :, 0])))\n",
    "        self.img = mip_rgb\n",
    "        if self.y_pred is not None:\n",
    "            self.layout, self.feats = vi.plotly_predictions(img=mip_rgb,\n",
    "                                                            bb=self.bb,\n",
    "                                                            y_pred=self.y_pred,\n",
    "                                                            target_names=self.target_names)\n",
    "        else:\n",
    "            self.layout, self.feats = vi.plotly_viz(img=mip_rgb,\n",
    "                                                    bb=self.bb)\n",
    "        return self\n",
    "\n",
    "    # plot predictions overlaid with the original image\n",
    "    # plot is a 'void' function (returns 'None')\n",
    "    def plot(self):\n",
    "        iplot(dict(data=self.feats, layout=self.layout))\n",
    "\n",
    "    # update scene after refitting the pipeline\n",
    "    def update_scene(self):\n",
    "        self.feats = vi.update_feats(img=self.img,\n",
    "                                     bb=self.bb,\n",
    "                                     y_pred=self.y_pred,\n",
    "                                     target_names=self.target_names)\n",
    "        return self\n",
    "\n",
    "    def add_instances(self, newlabels):\n",
    "        if self.newlabels is None:\n",
    "            self.newlabels = newlabels\n",
    "        else:\n",
    "            a1_rows = newlabels.view(\n",
    "                [('', newlabels.dtype)] * newlabels.shape[1])\n",
    "            a2_rows = self.newlabels.view(\n",
    "                [('', self.newlabels.dtype)] * self.newlabels.shape[1])\n",
    "\n",
    "            self.newlabels = newlabels\n",
    "            newlabels = (np.setdiff1d(a1_rows, a2_rows).\n",
    "                         view(newlabels.dtype).\n",
    "                         reshape(-1, newlabels.shape[1]))\n",
    "\n",
    "        if newlabels.size:\n",
    "            cellbb_new = [self.cellbb[i] for i in newlabels[:, 0]]\n",
    "            cellbb_new_norm = [resize(cb, (self.w, self.h), anti_aliasing=True)\n",
    "                               for cb in cellbb_new]\n",
    "            X_new_norm = np.array([cbn.ravel() for cbn in cellbb_new_norm])\n",
    "\n",
    "            self.X_train_norm = np.concatenate((self.X_train_norm, X_new_norm))\n",
    "            self.y_train = np.append(self.y_train, newlabels[:, 1])\n",
    "\n",
    "            X_prop_list = [get_regionprop_feats(\n",
    "                mip_rgb=cbb, exclude=exclude) for cbb in cellbb_new]\n",
    "            X_new_prop = np.vstack(X_prop_list)\n",
    "            self.X_train_prop = np.concatenate((self.X_train_prop, X_new_prop))\n",
    "        return self\n",
    "\n",
    "    # print the confusion matrix on the existing training set\n",
    "    def get_classifiction_report(self):\n",
    "        X_train_pca = self.pca.transform(self.X_train_norm)\n",
    "        X_train_all = np.append(X_train_pca, self.X_train_prop, axis=1)\n",
    "        y_pred = self.clf.predict(X_train_all)\n",
    "        print(classification_report(self.y_train,\n",
    "                                    y_pred, target_names=self.target_names))\n",
    "        print(confusion_matrix(self.y_train, y_pred,\n",
    "                               labels=range(len(self.target_names))))\n",
    "        return self\n",
    "\n",
    "    def get_cross_val_score(self, kfold=5):\n",
    "        X_train_pca = self.pca.transform(self.X_train_norm)\n",
    "        X_train_all = np.append(X_train_pca, self.X_train_prop, axis=1)\n",
    "        scores = cross_val_score(self.clf, X_train_all, self.y_train, cv=kfold)\n",
    "        print scores\n",
    "\n",
    "        return self\n",
    "\n",
    "    def reset(self):\n",
    "        self.newlabels = None\n",
    "        self.X_test_norm = None\n",
    "        self.X_test_prop = None\n",
    "        return self\n",
    "\n",
    "    def h5_write(self, fname):\n",
    "        hf = h5py.File(fname, 'w')\n",
    "        hf.create_dataset('X_train_norm', data=self.X_train_norm)\n",
    "        hf.create_dataset('X_train_prop', data=self.X_train_prop)\n",
    "        hf.create_dataset('y_train', data=self.y_train)\n",
    "        hf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# old version of the function\n",
    "def compute_props(self):\n",
    "        X_prop_list =  [OT.get_regionprop_feats(mip_rgb=cbb,\n",
    "                                                exclude=exclude) for cbb in cellbb_train]\n",
    "        X_train_prop = np.vstack(X_prop_list)\n",
    "\n",
    "\n",
    "        cellbb_norm = [resize(cb, (w, h), anti_aliasing=True) for cb in cellbb_train]\n",
    "        X_train_norm = np.array([cbn.ravel() for cbn in cellbb_norm])\n",
    "        # compute PCA of the image data set\n",
    "        n_components = 150\n",
    "        pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "                  whiten=True).fit(X_train_norm)\n",
    "\n",
    "        # project the train data\n",
    "        X_train_pca = pca.transform(X_train_norm)\n",
    "\n",
    "        X_train_all = np.append(X_train_pca, X_train_prop, axis=1)\n",
    "        \n",
    "        return self'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify `IncrementalClassifier` class to adapt to our use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incremental (\"online\") classifier\n",
    "clf_incr = OT.IncrementalClassifier(path=path, featdir=featdir,\n",
    "                                 select_well=select_inst[0],\n",
    "                                 target_names=target_names,\n",
    "                                 X_train_norm=X_train_norm,\n",
    "                                 X_train_prop=X_train_prop,\n",
    "                                 y_train=y_train\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_incr = (clf_incr.load_img().\n",
    "            train_classifier().\n",
    "           generate_predictions().\n",
    "           set_scene())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_incr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlabels = np.array([[45,2], [91,5], [85,0], [2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_incr = (clf_incr.\n",
    "            add_instances(newlabels=newlabels).\n",
    "            train_classifier().\n",
    "            generate_predictions().update_scene())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
