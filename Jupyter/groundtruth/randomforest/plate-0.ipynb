{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label image data in plate 180528_Plate3\n",
    "*Vladislav Kim*\n",
    "\n",
    "\n",
    "* [Introduction](#1)\n",
    "* [Initial training set](#2)\n",
    "\n",
    "<a id=\"1\"></a> \n",
    "## Introduction\n",
    "The idea of this notebook series is to train a pseudo-online random forest classifier for AML vs stroma cell classification. From selected plates we (for now) sample 6 DMSO wells with the highest Calcein cell count, generate predictions and correct misclassified instances and check in live (\"online\") mode how the predictions improve as we add more data. Note that the classifier is not truly an online classifier as we don't update the model as we go, but completely retrain the RF classfier in multicore mode.\n",
    "\n",
    "In general we can implement targeted online learning strategy: we can select a number of wells that are of interest to us (target wells), e.g. DMSO control wells or wells with certain high-priority drugs, the accuracy of which we want to improve, in the first place. We sample from these target wells from selected plates and evaluate the classification accuracy as we go (pseudo online learning).\n",
    "\n",
    "\n",
    "<a id=\"2\"></a>\n",
    "## Initial Training Set: 180528_Plate3\n",
    "At first we will re-train the classifier on the plate `180528_Plate3`, as it manifests a very striking contrast between mono- and co-cultures. We want to rule out the fact that this could be a segmentation (classification in this case) artefact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load third-party Python modules\n",
    "import javabridge\n",
    "import bioformats as bf\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../..')\n",
    "\n",
    "javabridge.start_vm(class_path=bf.JARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.utils import load_imgstack\n",
    "imgstack = load_imgstack(fname=\"../../data/AML_trainset/180528_Plate3/r02c14.tiff\")\n",
    "\n",
    "# remove a 'dummy' z-axis\n",
    "img = np.squeeze(imgstack)\n",
    "\n",
    "# nuclei\n",
    "hoechst = img[:,:,0]**0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/AML_trainset/180528_Plate3/r02c14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment.tools import read_bbox\n",
    "rmax, cmax = hoechst.shape\n",
    "\n",
    "bbox = read_bbox(df=df, rmax=rmax, cmax=cmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.plot import show_bbox\n",
    "#show_bbox(hoechst, bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotly visualization works!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extra.viz import plotly_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_adapthist\n",
    "gamma = 0.3\n",
    "img_g = img**gamma\n",
    "mip_rgb = equalize_adapthist(np.dstack((img_g[:,:,1],\n",
    "                                        img_g[:,:,2],\n",
    "                                        img_g[:,:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout, cells = plotly_viz(mip_rgb, bb=bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extra.viz import plotly_predictions\n",
    "ypred = np.zeros(len(bbox), dtype=np.int)\n",
    "labels = ['cells']\n",
    "layout, cells = plotly_predictions(img=mip_rgb, bb=bbox,\n",
    "                                  ypred=ypred, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iplot(dict(data=cells, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_instance(path, fname, pad=0):\n",
    "    imgstack = load_imgstack(fname=os.path.join(path, fname + \".tiff\"),\n",
    "                            verbose=False)\n",
    "    img = np.squeeze(imgstack)\n",
    "    df = pd.read_csv(os.path.join(path, fname + \".csv\"))\n",
    "    rmax, cmax, _ = img.shape\n",
    "    bbox = read_bbox(df=df, rmax=rmax,\n",
    "                     cmax=cmax, pad=pad)\n",
    "    return img, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, bbox = get_train_instance(path='../../data/AML_trainset/180528_Plate3',\n",
    "                              fname='r02c14', pad=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here need to fix how we import `ImgX`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../../')\n",
    "from bioimg.classify import ImgX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgx_test = ImgX(img=img**0.4, bbox=bbox, n_chan=3)\n",
    "imgx_test = imgx_test.compute_props()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgx_test.data[0].iloc[:10,:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement a class that has `ImgX` instance and can accumulate training data:**\n",
    "+ Should we initialize the classifier from within the class or should users pass the classifier to `IncrementalClassifier` constructor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class IncrementalClassifier:\n",
    "    def __init__(self):\n",
    "        # initialize with 'None' something to be loaded later\n",
    "        self.imgx = None\n",
    "        \n",
    "        # for the plotly visualization\n",
    "        self.feats = None\n",
    "        self.layout = None\n",
    "        \n",
    "        self.newlabels = None\n",
    "        # training data\n",
    "        self.Xtrain = None\n",
    "        self.ytrain = None\n",
    "        # inialize classifier as 'None'\n",
    "        self.clf = None\n",
    "        self.classes = None\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self.__dict__[name] = value\n",
    "        # if a new ImgX object is passed,\n",
    "        # compute its features\n",
    "        if name == 'imgx':\n",
    "            self._compute_imgx_data()\n",
    "\n",
    "    # function for setting individual class parameters\n",
    "    def set_param(self, **kwargs):\n",
    "        for k in kwargs.keys():\n",
    "            self.__setattr__(k, kwargs[k])\n",
    "         \n",
    "    # internal function checks if the embedded\n",
    "    # imgx object has the features computed\n",
    "    def _compute_imgx_data(self):\n",
    "        if self.imgx is not None and len(self.imgx.data) == 0:\n",
    "            self.imgx.compute_props()\n",
    "            \n",
    "    # set plotly graphical layers\n",
    "    def set_scene(self):\n",
    "        if self.imgx.y is not None:\n",
    "            self.layout, self.feats = plotly_predictions(img=self.imgx.img,\n",
    "                                                         bb=self.imgx.bbox,\n",
    "                                                         ypred=self.imgx.y\n",
    "                                                        )\n",
    "        else:\n",
    "            self.layout, self.feats = plotly_viz(img=self.imgx.img,\n",
    "                                                    bb=self.imgx.bbox)\n",
    "        return self\n",
    "\n",
    "    # plot predictions overlaid with the original image\n",
    "    # plot is a 'void' function (returns 'None')\n",
    "    def plot(self):\n",
    "        iplot(dict(data=self.feats, layout=self.layout))\n",
    "        \n",
    "    def add_instances(self, newlabels):\n",
    "        newlabels = np.unique(newlabels, axis=0)\n",
    "        if self.newlabels is None:\n",
    "            self.newlabels = newlabels\n",
    "        else:\n",
    "            a1_rows = newlabels.view(\n",
    "                [('', newlabels.dtype)] * newlabels.shape[1])\n",
    "            a2_rows = self.newlabels.view(\n",
    "                [('', self.newlabels.dtype)] * self.newlabels.shape[1])\n",
    "\n",
    "            newlabels = (np.setdiff1d(a1_rows, a2_rows).\n",
    "                         view(newlabels.dtype).\n",
    "                         reshape(-1, newlabels.shape[1]))\n",
    "            self.newlabels = np.append(self.newlabels, newlabels, axis=0)\n",
    "        return self\n",
    "    \n",
    "    def _get_traindata(self):\n",
    "        ids = self.newlabels[:,0]\n",
    "        data_dict = self.imgx.data\n",
    "        for k,v in data_dict.items():\n",
    "            v.columns = ['-'.join(['ch', str(k), col]) for col in v.columns.values]\n",
    "        data = pd.concat(data_dict, axis=1)\n",
    "        data.columns = data.columns.droplevel()\n",
    "        \n",
    "        self.Xtrain = data.iloc[ids,:]\n",
    "        self.ytrain = label_binarize(self.newlabels[:,1], classes=self.classes)\n",
    "        \n",
    "    def set_classifier(self, clf=None):\n",
    "            self.clf = clf\n",
    "            # if 'None' then some reasonable default\n",
    "            if clf is None:\n",
    "                self.clf = OneVsRestClassifier(RandomForestClassifier(bootstrap=True,\n",
    "                                                  class_weight=\"balanced\",\n",
    "                                                  n_estimators=500,\n",
    "                                                  random_state=123,\n",
    "                                                  n_jobs=-1))\n",
    "            return self\n",
    "    \n",
    "    def train_classifier(self):\n",
    "        self._get_traindata()\n",
    "        self.clf.fit(self.Xtrain, self.ytrain)\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sort the `img` array so that the color channel order is RGB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.4\n",
    "# adjust brightness by gamma correction\n",
    "img_g = img**gamma\n",
    "# sort color channels in'RGB' order\n",
    "img_rgb = np.dstack((img_g[:,:,1],\n",
    "                     img_g[:,:,2],\n",
    "                     img_g[:,:,0]))\n",
    "# initialize 'ImgX' class\n",
    "imgx = ImgX(img=img_rgb, bbox=bbox, n_chan=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_incr = IncrementalClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_incr.imgx = imgx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_incr.set_scene().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlabels = np.array([[43,1], [48,1], [29,1],\n",
    "                      [55,1], [123,0], [76,0], \n",
    "                      [82,0], [82,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_incr = clf_incr.add_instances(newlabels=newlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So `_get_traindata` works apparently, call it before `train_classifier`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_incr._get_traindata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add `OneVsRestClassifier` and binarize the target variable `y`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions with the loaded feature data\n",
    "def generate_predictions(self, prob=False):\n",
    "    if self.X_test_norm is None:\n",
    "        cellbb_norm = [resize(cb, (self.w, self.h), anti_aliasing=True)\n",
    "                       for cb in self.cellbb]\n",
    "        self.X_test_norm = np.array([cbn.ravel() for cbn in cellbb_norm])\n",
    "\n",
    "    if self.X_test_prop is None:\n",
    "        X_prop_list = [get_regionprop_feats(\n",
    "            mip_rgb=cbb, exclude=exclude) for cbb in self.cellbb]\n",
    "        self.X_test_prop = np.vstack(X_prop_list)\n",
    "\n",
    "    X_test_pca = self.pca.transform(self.X_test_norm)\n",
    "    X_test_all = np.append(X_test_pca, self.X_test_prop, axis=1)\n",
    "\n",
    "    self.y_pred = self.clf.predict(X_test_all)\n",
    "    if prob:\n",
    "        self.y_prob = self.clf.predict_proba(X_test_all)\n",
    "    return self\n",
    "\n",
    "\n",
    "# print the confusion matrix on the existing training set\n",
    "def get_classifiction_report(self):\n",
    "    X_train_pca = self.pca.transform(self.X_train_norm)\n",
    "    X_train_all = np.append(X_train_pca, self.X_train_prop, axis=1)\n",
    "    y_pred = self.clf.predict(X_train_all)\n",
    "    print(classification_report(self.y_train,\n",
    "                                y_pred, target_names=self.target_names))\n",
    "    print(confusion_matrix(self.y_train, y_pred,\n",
    "                           labels=range(len(self.target_names))))\n",
    "    return self\n",
    "\n",
    "def get_cross_val_score(self, kfold=5):\n",
    "    X_train_pca = self.pca.transform(self.X_train_norm)\n",
    "    X_train_all = np.append(X_train_pca, self.X_train_prop, axis=1)\n",
    "    scores = cross_val_score(self.clf, X_train_all, self.y_train, cv=kfold)\n",
    "    print scores\n",
    "\n",
    "    return self\n",
    "\n",
    "def reset(self):\n",
    "    self.newlabels = None\n",
    "    self.X_test_norm = None\n",
    "    self.X_test_prop = None\n",
    "    return self\n",
    "\n",
    "def h5_write(self, fname):\n",
    "    hf = h5py.File(fname, 'w')\n",
    "    hf.create_dataset('X_train_norm', data=self.X_train_norm)\n",
    "    hf.create_dataset('X_train_prop', data=self.X_train_prop)\n",
    "    hf.create_dataset('y_train', data=self.y_train)\n",
    "    hf.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# old version of the function\n",
    "def compute_props(self):\n",
    "        X_prop_list =  [OT.get_regionprop_feats(mip_rgb=cbb,\n",
    "                                                exclude=exclude) for cbb in cellbb_train]\n",
    "        X_train_prop = np.vstack(X_prop_list)\n",
    "\n",
    "\n",
    "        cellbb_norm = [resize(cb, (w, h), anti_aliasing=True) for cb in cellbb_train]\n",
    "        X_train_norm = np.array([cbn.ravel() for cbn in cellbb_norm])\n",
    "        # compute PCA of the image data set\n",
    "        n_components = 150\n",
    "        pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "                  whiten=True).fit(X_train_norm)\n",
    "\n",
    "        # project the train data\n",
    "        X_train_pca = pca.transform(X_train_norm)\n",
    "\n",
    "        X_train_all = np.append(X_train_pca, X_train_prop, axis=1)\n",
    "        \n",
    "        return self'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify `IncrementalClassifier` class to adapt to our use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incremental (\"online\") classifier\n",
    "clf_incr = OT.IncrementalClassifier(path=path, featdir=featdir,\n",
    "                                 select_well=select_inst[0],\n",
    "                                 target_names=target_names,\n",
    "                                 X_train_norm=X_train_norm,\n",
    "                                 X_train_prop=X_train_prop,\n",
    "                                 y_train=y_train\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_incr = (clf_incr.load_img().\n",
    "            train_classifier().\n",
    "           generate_predictions().\n",
    "           set_scene())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_incr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlabels = np.array([[45,2], [91,5], [85,0], [2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_incr = (clf_incr.\n",
    "            add_instances(newlabels=newlabels).\n",
    "            train_classifier().\n",
    "            generate_predictions().update_scene())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
