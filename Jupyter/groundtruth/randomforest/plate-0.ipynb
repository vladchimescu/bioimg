{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label image data in plate 180528_Plate3\n",
    "*Vladislav Kim*\n",
    "\n",
    "\n",
    "* [Introduction](#1)\n",
    "* [Initial training set](#2)\n",
    "\n",
    "<a id=\"1\"></a> \n",
    "## Introduction\n",
    "The idea of this notebook series is to train a pseudo-online random forest classifier for AML vs stroma cell classification. From selected plates we (for now) sample 6 DMSO wells with the highest Calcein cell count, generate predictions and correct misclassified instances and check in live (\"online\") mode how the predictions improve as we add more data. Note that the classifier is not truly an online classifier as we don't update the model as we go, but completely retrain the RF classfier in multicore mode.\n",
    "\n",
    "In general we can implement targeted online learning strategy: we can select a number of wells that are of interest to us (target wells), e.g. DMSO control wells or wells with certain high-priority drugs, the accuracy of which we want to improve, in the first place. We sample from these target wells from selected plates and evaluate the classification accuracy as we go (pseudo online learning).\n",
    "\n",
    "\n",
    "<a id=\"2\"></a>\n",
    "## Initial Training Set: 180528_Plate3\n",
    "At first we will re-train the classifier on the plate `180528_Plate3`, as it manifests a very striking contrast between mono- and co-cultures. We want to rule out the fact that this could be a segmentation (classification in this case) artefact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load third-party Python modules\n",
    "import javabridge\n",
    "import bioformats as bf\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../..')\n",
    "\n",
    "javabridge.start_vm(class_path=bf.JARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.utils import load_imgstack\n",
    "imgstack = load_imgstack(fname=\"../../data/AML_trainset/180528_Plate3/r02c14.tiff\")\n",
    "\n",
    "# remove a 'dummy' z-axis\n",
    "img = np.squeeze(imgstack)\n",
    "\n",
    "# nuclei\n",
    "hoechst = img[:,:,0]**0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/AML_trainset/180528_Plate3/r02c14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment.tools import read_bbox\n",
    "rmax, cmax = hoechst.shape\n",
    "\n",
    "bbox = read_bbox(df=df, rmax=rmax, cmax=cmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.plot import show_bbox\n",
    "#show_bbox(hoechst, bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotly visualization works!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extra.viz import plotly_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_adapthist\n",
    "gamma = 0.3\n",
    "img_g = img**gamma\n",
    "mip_rgb = equalize_adapthist(np.dstack((img_g[:,:,1],\n",
    "                                        img_g[:,:,2],\n",
    "                                        img_g[:,:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout, cells = plotly_viz(mip_rgb, bb=bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extra.viz import plotly_predictions\n",
    "ypred = np.zeros(len(bbox), dtype=np.int)\n",
    "labels = ['cells']\n",
    "layout, cells = plotly_predictions(img=mip_rgb, bb=bbox,\n",
    "                                  ypred=ypred, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iplot(dict(data=cells, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_instance(path, fname, pad=0):\n",
    "    imgstack = load_imgstack(fname=os.path.join(path, fname + \".tiff\"),\n",
    "                            verbose=False)\n",
    "    img = np.squeeze(imgstack)\n",
    "    df = pd.read_csv(os.path.join(path, fname + \".csv\"))\n",
    "    rmax, cmax, _ = img.shape\n",
    "    bbox = read_bbox(df=df, rmax=rmax,\n",
    "                     cmax=cmax, pad=pad)\n",
    "    return img, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, bbox = get_train_instance(path='../../data/AML_trainset/180528_Plate3',\n",
    "                              fname='r02c14', pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellbb = [img[x[2]:x[3], x[0]:x[1],0] for x in bbox]\n",
    "cell = cellbb[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.process import threshold_img\n",
    "bw = threshold_img(cell, method='otsu', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.future_versions import regionprops_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['area',\n",
    " 'bbox',\n",
    " 'bbox_area',\n",
    " 'centroid',\n",
    " 'convex_area',\n",
    " 'eccentricity',\n",
    " 'equivalent_diameter',\n",
    " 'euler_number',\n",
    " 'filled_area',\n",
    " 'major_axis_length',\n",
    " 'minor_axis_length',\n",
    " 'moments',\n",
    " 'moments_central',\n",
    " 'moments_hu',\n",
    " 'moments_normalized',\n",
    " 'orientation',\n",
    " 'perimeter',\n",
    " 'solidity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "\n",
    "## create a data frame with texture features\n",
    "glcm_props = ['contrast', 'dissimilarity',\n",
    "              'ASM', 'energy', 'correlation']\n",
    "\n",
    "def glcm_to_dataframe(glcm, prop):\n",
    "    '''Compute GLCM property\n",
    "    '''\n",
    "    mat = greycoprops(glcm, prop=prop)\n",
    "    columns = ['-'.join([prop, str(i)]) for i in range(len(mat.ravel()))]\n",
    "    return pd.DataFrame(mat.ravel().reshape(1,-1),\n",
    "                       columns=columns)\n",
    "\n",
    "\n",
    "def compute_region_props(cell, keys,\n",
    "                         distances=[3, 5, 7],\n",
    "                         angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    bw = threshold_img(cell, method='otsu', binary=True)\n",
    "    df = pd.DataFrame(regionprops_table(bw.astype('int'),\n",
    "                                        cell, properties=keys))\n",
    "    \n",
    "    glcm = greycomatrix(img_as_ubyte(cell),\n",
    "                        distances=distances,\n",
    "                        angles=angles)\n",
    "    texture_df = pd.concat([glcm_to_dataframe(glcm, prop=p) for p in glcm_props],axis=1)\n",
    "    \n",
    "    \n",
    "    return pd.concat([df, texture_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_region_props(cell=cell, keys=keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we assume that an img is a 3D array with the last axis corresponding to color information. Thus for our leukemia data the size of each image array is: `(2160, 2160, 3)`. **Need to carefully compute features for this case** Should the properties be computed for each channel separately? **Also the functions should work for greyscale images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "\n",
    "class ImgX:\n",
    "    def __init__(self, img, bbox, y=None):\n",
    "        self.img = img\n",
    "        self.bbox = bbox\n",
    "        self.y = y\n",
    "        \n",
    "        self.data = None\n",
    "        self.target_names = None\n",
    "        \n",
    "    def __setattr__(self, name, value):\n",
    "        self.__dict__[name] = value\n",
    "\n",
    "    def set_param(self, **kwargs):\n",
    "        for k in kwargs.keys():\n",
    "            self.__setattr__(k, kwargs[k])\n",
    "        return self\n",
    "    \n",
    "    def _get_features(self, img):\n",
    "        # compute features for all the bboxes\n",
    "        return self\n",
    "        \n",
    "    def compute_props(self, n_chan, split=True):\n",
    "        # split=True means that the color channels will be split and the\n",
    "        # properties will be computed for each channel separately\n",
    "        if n_chan > 1 and split:\n",
    "            for c in range(n_chan):\n",
    "                self._get_features(img=img[:,:,c])\n",
    "        \n",
    "        else:\n",
    "            img_gray = rgb2gray(img)\n",
    "            self._get_features(img=img_gray)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version of the function\n",
    "def compute_props(self):\n",
    "        X_prop_list =  [OT.get_regionprop_feats(mip_rgb=cbb,\n",
    "                                                exclude=exclude) for cbb in cellbb_train]\n",
    "        X_train_prop = np.vstack(X_prop_list)\n",
    "\n",
    "\n",
    "        cellbb_norm = [resize(cb, (w, h), anti_aliasing=True) for cb in cellbb_train]\n",
    "        X_train_norm = np.array([cbn.ravel() for cbn in cellbb_norm])\n",
    "        # compute PCA of the image data set\n",
    "        n_components = 150\n",
    "        pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "                  whiten=True).fit(X_train_norm)\n",
    "\n",
    "        # project the train data\n",
    "        X_train_pca = pca.transform(X_train_norm)\n",
    "\n",
    "        X_train_all = np.append(X_train_pca, X_train_prop, axis=1)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify `IncrementalClassifier` class to adapt to our use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incremental (\"online\") classifier\n",
    "clf_incr = OT.IncrementalClassifier(path=path, featdir=featdir,\n",
    "                                 select_well=select_inst[0],\n",
    "                                 target_names=target_names,\n",
    "                                 X_train_norm=X_train_norm,\n",
    "                                 X_train_prop=X_train_prop,\n",
    "                                 y_train=y_train\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_incr = (clf_incr.load_img().\n",
    "            train_classifier().\n",
    "           generate_predictions().\n",
    "           set_scene())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_incr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlabels = np.array([[45,2], [91,5], [85,0], [2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_incr = (clf_incr.\n",
    "            add_instances(newlabels=newlabels).\n",
    "            train_classifier().\n",
    "            generate_predictions().update_scene())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
