{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object-based Image Classification\n",
    "*Author: Vladislav Kim*\n",
    "* [Introduction](#intro)\n",
    "* [Leukemia coculture screen](#coculture)\n",
    "* [Generate initial segmentation](#initialsegm)\n",
    "* [Image labelling](#label)\n",
    "* [Training and test set generation](#trainset)\n",
    "* [Random forest classifier](#randomforest)\n",
    "* [Parameter tuning and feature selection](#featureselect)\n",
    "* [Comparison with other classifiers](#comparison)\n",
    "\n",
    "\n",
    "<a id=\"intro\"></a> \n",
    "## Introduction\n",
    "Segmentation using classical computer vision approaches such as watershed may produce results that have to be filtered based on their region properties to eliminate segmentation artefacts, such as small objects, noise, etc. If the image set is large (such as in high-throughput screening), filtering based on fixed thresholds may produce supoptimal results with lots of variance. In order to automate the task of filtering artefacts we can resort to machine learning approaches. \n",
    "\n",
    "\n",
    "There is a number of different schemes and machine learning models that can be used for this purpose. Here we will show how to train an object-based random forest classifier. The input for this classifier will be cropped bounding regions of the initial segmentation generated by simple connected component labelling. The task will be to classify the image patches into various cell types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load third-party Python modules\n",
    "import javabridge\n",
    "import bioformats as bf\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "javabridge.start_vm(class_path=bf.JARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"coculture\"></a> \n",
    "## Leukemia coculture screen\n",
    "Here we are dealing with coculture images with 2 cell types: stroma and leukemia cells, which were not stained differentially. Primary leukemia cells are small, somewhat circular. The stroma cells are large and may take on various shapes. Due to this minimal staining palette we need to use machine learning to automate the process of identification of leukemia cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.utils import load_imgstack\n",
    "imgstack = load_imgstack(fname=\"data/AML_trainset/180528_Plate3/r02c14.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a 'dummy' z-axis\n",
    "img = np.squeeze(imgstack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will visualize 3 color channels individually:\n",
    "* Hoechst stains nuclei\n",
    "* Lysosomal dye marks lysosomal compartments\n",
    "* Calcein stains only viable cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.plot import plot_channels\n",
    "gamma = 0.4\n",
    "plot_channels([img[:,:,i]**gamma for i in range(3)],\n",
    "              nrow=1, ncol=3, cmap='gray',\n",
    "              titles=['Hoechst', 'Lysosomal dye', 'Viability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.plot import combine_channels\n",
    "\n",
    "img_rgb = combine_channels([img[:,:,i] for i in range(3)],\n",
    "                            colors=['blue', 'red', 'green'],\n",
    "                            blend=[1.5,1.5,2],\n",
    "                            gamma=[0.6, 0.6,0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"initialsegm\"></a> \n",
    "## Generate initial segmentation\n",
    "We can generate initial segmentation using simple connected component labelling in the nucleus channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.process import threshold_img\n",
    "hoechst = img[:,:,0]**gamma\n",
    "img_th = threshold_img(hoechst, method='otsu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_th)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply morphological erosion in order to shrink adjacent boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_erosion, disk\n",
    "img_th = binary_erosion(threshold_img(hoechst, binary=True, method='otsu'), disk(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use connencted component labelling and visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "from skimage.color import label2rgb\n",
    "segm = label(img_th, connectivity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm, image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy here would be to subset the labelled regions based on their properties (area and perimeter). Since most leukemia nulcei are smaller than stroma nuclei, we can use a range of values: about 6 to 30 micron for the radius of leukemia nucleus candidates. Define a `dict` of lower and upper bounds for the features `area` and `perimeter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = {'area': (500, 6000), 'perimeter': (100, 1000)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`filter_segm` function subsets the labelled regions based on the defined lower and upper `bounds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment.cv_methods import filter_segm\n",
    "segm1 = filter_segm(img=hoechst, labels=segm, bounds=bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus large  (`area > 6000` and `perimeter > 1000`) and small (`area < 500` and `perimeter < 100`) regions were removed and only medium-size objects (presumably leukemia nuclei) were retained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm1, image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some of the small nuclei are missing as these are overlapping with the larger stroma nuclei. In order to address this  search for bright spots (apoptotic nuclei) in the mask with bigger regions. The approach we take here is to \"break up\" large objects into smaller chunks and these can be further prefiltered by intensity for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = filter_segm(img=hoechst, labels=segm, bounds={'area': (6000, np.inf)}) +\\\n",
    "filter_segm(img=hoechst, labels=segm, bounds={'perimeter': (1000, np.inf)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(big, image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_obj = hoechst*np.isin(segm, np.unique(big[big != 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `white_tophat` filter which only preserves bright spots with the radius $<25$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import white_tophat\n",
    "from skimage.morphology import remove_small_objects\n",
    "img_tophat = white_tophat(big_obj, disk(25))\n",
    "# bright spots from the large regions that were filtered out\n",
    "# in the previous step\n",
    "segm2 = remove_small_objects(threshold_img(img_tophat, method='yen', binary=True),\n",
    "                                min_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(segm2)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge these brigh spots from large regions with the regions in `segm1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only non-background pixels\n",
    "segm1 = (segm1 != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_out = label(np.logical_or(segm1, segm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(label2rgb(segm_out, image=hoechst, bg_label=0))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these merged labelled regions that were filtered by size as our initial segmentation and use machine learning to refine the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "feats_out =  regionprops(label_image=segm_out, intensity_image=hoechst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract bounding box coordinates for each labelled region and visualize these bounding boxes in the RGB image (with padding `pad = 20`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 20\n",
    "bbox = []\n",
    "\n",
    "for f in feats_out:\n",
    "    ymin, xmin, ymax, xmax = f.bbox\n",
    "    bb = np.array((max(0, xmin - pad),\n",
    "                  min(xmax + pad, hoechst.shape[0] - 1),\n",
    "                  max(0, ymin - pad),\n",
    "                  min(ymax + pad, hoechst.shape[0] - 1)))\n",
    "    bbox.append(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_out[0].bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(feats_out) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.plot import show_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bbox(img_rgb, bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we capture mostly viable and apoptotic leukemia cells in this initial segmentation, however there is an appreciable number of stroma cell fragments in this image. Another complication is that there is a couple of apoptotic leukemia nuclei overlapping with the stroma cells. Should we naively label all Calcein-positive cells as viable, we will run into the problem that apoptotic leukemia cells overlapping with Calcein-stained stroma will be falsely counted as viable.  This is why we will train a classifier to recognize such cases (both stroma cell fragments as well as dead leukemia cells overlapping with Calcein-positive stroma)\n",
    "\n",
    "\n",
    "Now we need to store both bounding box coordinates as well as region properties for each image patch and we need an easy (and scalable) way of retrieving bounding box information for each image. First generate a table (`DataFrame`) with all the information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.future_versions import regionprops_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [k for k in feats_out[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['convex_image', 'coords', 'extent',\n",
    "           'filled_image', 'image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_keys = list(set(keys) - set(exclude))\n",
    "# sort by key lexicographically\n",
    "selected_keys.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = regionprops_table(segm_out,\n",
    "                       intensity_image=hoechst,\n",
    "                      properties=selected_keys)\n",
    "\n",
    "feat_df = pd.DataFrame(feat_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df.iloc[:6,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_df.to_csv(\"data/AML_trainset/180528_Plate3/r02c14.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"label\"></a> \n",
    "## Image labelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/AML_trainset/180528_Plate3/r02c14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment.tools import read_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmax, cmax = hoechst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'bbox-0': 'ymin',\n",
    "                   'bbox-1': 'xmin',\n",
    "                   'bbox-2': 'ymax',\n",
    "                   'bbox-3': 'xmax'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = read_bbox(df=df, rmax=rmax, cmax=cmax, pad=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bbox(img_rgb, bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trainset\"></a> \n",
    "## Training and test set generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"randomforest\"></a> \n",
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"featureselect\"></a> \n",
    "## Parameter tuning and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparison\"></a> \n",
    "## Comparison with other classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
