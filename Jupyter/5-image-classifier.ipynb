{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object-based Image Classification\n",
    "*Author: Vladislav Kim*\n",
    "* [Introduction](#intro)\n",
    "* [Generate initial segmentation](#initialsegm)\n",
    "* [Image labelling](#label)\n",
    "* [Training and test set generation](#trainset)\n",
    "* [Random forest classifier](#randomforest)\n",
    "* [Parameter tuning and feature selection](#featureselect)\n",
    "* [Comparison with other classifiers](#comparison)\n",
    "\n",
    "\n",
    "<a id=\"intro\"></a> \n",
    "## Introduction\n",
    "Segmentation using classical computer vision approaches such as watershed may produce results that have to be filtered based on their region properties to eliminate segmentation artefacts, such as small objects, noise, etc. If the image set is large (such as in high-throughput screening), filtering based on fixed thresholds may be supoptimal. In order to automate the task of filtering artefacts we can resort to machine learning approaches. \n",
    "\n",
    "\n",
    "There is a number of different schemes and machine learning models that can be used for this purpose. Here we will show how to train an object-based random forest classifier. The input for this classifier will be cropped bounding regions of the initial segmentation generated by simple spot detection. The task will be to classify the image patches into various cell types. \n",
    "\n",
    "Here we are dealing with coculture images with 2 cell types: stroma and leukemia cells, which were not stained differentially. Due to this minimal staining palette we need to use machine learning to automate the process of identification of leukemia cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load third-party Python modules\n",
    "import javabridge\n",
    "import bioformats as bf\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "javabridge.start_vm(class_path=bf.JARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.utils import load_imgstack\n",
    "imgstack = load_imgstack(fname=\"data/AML_trainset/180528_Plate3/r02c14.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a 'dummy' z-axis\n",
    "img = np.squeeze(imgstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.plot import plot_channels\n",
    "gamma = 0.4\n",
    "plot_channels([img[:,:,i]**gamma for i in range(3)],\n",
    "              nrow=1, ncol=3, cmap='gray',\n",
    "              titles=['Hoechst', 'Lysosomal dye', 'Viability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.plot import combine_channels\n",
    "\n",
    "img_rgb = combine_channels([img[:,:,i] for i in range(3)],\n",
    "                            colors=['blue', 'red', 'green'],\n",
    "                            blend=[1.5,1.5,2],\n",
    "                            gamma=[0.6, 0.6,0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"initialsegm\"></a> \n",
    "## Generate initial segmentation\n",
    "We can generate initial segmentation using spot detection in the nucleus channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.process import threshold_img\n",
    "hoechst = img[:,:,0]**gamma\n",
    "img_th = threshold_img(hoechst, method='otsu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_th)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_erosion, disk\n",
    "img_th = binary_erosion(threshold_img(hoechst, binary=True, method='otsu'), disk(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "from skimage.color import label2rgb\n",
    "segm = label(img_th, connectivity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm, image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "feats =  regionprops(label_image=segm, intensity_image=hoechst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feattable(feats, keys):\n",
    "    return pd.DataFrame({key: [f[key] for f in feats] for key in keys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = get_feattable(feats, keys=['area', 'eccentricity', 'mean_intensity', 'perimeter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = np.logical_and(feat_df.area < 6000, feat_df.perimeter < 1000)\n",
    "lower = np.logical_and(feat_df.area > 100, feat_df.perimeter > 50)\n",
    "feat_subset = np.logical_and(lower, upper)\n",
    "# label count of non-background objects starts with 1\n",
    "label_subset = np.where(feat_subset)[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm*np.isin(segm, label_subset), image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_segm(labels, bounds):\n",
    "    '''Subset labelled pixel map (segmentation)\n",
    "       ----------------------------------------\n",
    "       The function allows to subset the segmentation\n",
    "       by providing lower and upper bounds of various\n",
    "       region properties\n",
    "\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       labels : (nrow, ncol) array\n",
    "           Labelled image (generated by segmentation)\n",
    "       bounds : dict\n",
    "           Dictionary with keys naming features (regionprops)\n",
    "            and values providing lower and upper bounds\n",
    "\n",
    "\n",
    "       Returns\n",
    "       -------\n",
    "       segm_out : (nrow, ncol) array\n",
    "           Filtered labelled array\n",
    "        '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(filter_segm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, add these to the initial candidate pool. Deal with the large objects: search for bright spots (apoptotic nuclei) in the mask that only has large objects that were filtered out. The approach we take here is to \"break up\" large objects into smaller chunks and these can be further prefiltered by intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = np.where(~upper)[0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(label2rgb(segm*np.isin(segm, big), image=hoechst, bg_label=0))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(hoechst*np.isin(segm, big))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import white_tophat\n",
    "img_tophat = white_tophat(hoechst*np.isin(segm, big), disk(25))\n",
    "img_tophat_th = threshold_img(img_tophat, method='yen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_tophat_th)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import remove_small_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(remove_small_objects(threshold_img(img_tophat, method='yen', binary=True),\n",
    "                                min_size=500))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge these together with the other spots, generate (cropped) bounding boxes of each \"cell\" candidate and label them in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm1 = np.isin(segm, label_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm2 = remove_small_objects(threshold_img(img_tophat, method='yen', binary=True),\n",
    "                                min_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_out = label(np.logical_or(segm1, segm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(label2rgb(segm_out, hoechst))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_out =  regionprops(label_image=segm_out, intensity_image=hoechst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 20\n",
    "bbox = []\n",
    "\n",
    "for f in feats_out:\n",
    "    ymin, xmin, ymax, xmax = f.bbox\n",
    "    bb = np.array((max(0, xmin - pad),\n",
    "                  min(xmax + pad, hoechst.shape[0] - 1),\n",
    "                  max(0, ymin - pad),\n",
    "                  min(ymax + pad, hoechst.shape[0] - 1)))\n",
    "    bbox.append(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(12,12))\n",
    "ax.imshow(img_rgb)\n",
    "for bb in bbox:\n",
    "    start = (bb[0], bb[2])\n",
    "    extent = (bb[1] - bb[0],\n",
    "              bb[3] - bb[2])\n",
    "    rec = plt.Rectangle(xy=start,\n",
    "                 width = extent[1],\n",
    "                 height = extent[0],color = \"white\",\n",
    "                 linewidth=2, fill=False)\n",
    "    ax.add_patch(rec)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to store both bounding box coordinates as well as region properties for each image patch and we need an easy (and scalable) way of retrieving bounding box information for each image.\n",
    "\n",
    "First generate a table (`DataFrame`) with all the information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.future_versions import regionprops_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [k for k in feats_out[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['convex_image', 'coords', 'extent',\n",
    "           'filled_image', 'image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_keys = list(set(keys) - set(exclude))\n",
    "# sort by key lexicographically\n",
    "selected_keys.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = regionprops_table(segm_out,\n",
    "                       intensity_image=hoechst,\n",
    "                      properties=selected_keys)\n",
    "\n",
    "feat_df = pd.DataFrame(feat_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df.iloc[:6,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df.to_csv(\"data/AML_trainset/180528_Plate3/r02c14.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"label\"></a> \n",
    "## Image labelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trainset\"></a> \n",
    "## Training and test set generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"randomforest\"></a> \n",
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"featureselect\"></a> \n",
    "## Parameter tuning and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparison\"></a> \n",
    "## Comparison with other classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
